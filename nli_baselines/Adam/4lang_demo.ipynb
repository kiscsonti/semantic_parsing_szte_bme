{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4lang demo\n",
    "\n",
    "My baseline builds on the 4lang project available on [github](https://github.com/kornai/4lang). Our idea was to use the concept of the\n",
    "[4lang](https://github.com/kornai/4lang) graphs.\n",
    "\n",
    "In this notebook I only present the client side of our baseline, the code of the webservice is available on [github](https://github.com/adaamko/4lang). I will present a simple way of using the 4lang graphs for inference. For this task we can calculate similarities among the graphs edges built from the premise and the hypothesis sentences.\n",
    "\n",
    "If we are ready to make an assumption an inference corresponds with the similarity of the graphs's edges, then this simple method works for a lot of examples, but if we want higher accuracy, we need to define finer techniques. This is where the definitions of the words come into play.\n",
    "\n",
    "The base url of our service: http://4lang.mokk.bme.hu\n",
    "\n",
    "Currently our service has three endpoints, with each of them representing different methods:\n",
    "\n",
    "*  __/default__ - Returns the graphs built from the sentences.\n",
    "*  __/expand__ - Returns the graphs, where the word's definition has been added to the graph.\n",
    "*  __/abstract__ - Calling this function, we defined some rules, where we can build a more abstract graph using the definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import matplotlib\n",
    "import re\n",
    "import pydot\n",
    "from graphviz import Digraph\n",
    "from graphviz import Source\n",
    "from utils import Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define any two sentences we want the graph to be build on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = 'My poor wife!'\n",
    "hypothesis = 'I feel bad for my wife!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have the sentences we need to construct our json, and set the headers as well.\n",
    "The endpoint expects the jason to have the following format:\n",
    "\n",
    "    {    \n",
    "        'prem': 'sentence1',       \n",
    "        'hyp': 'sentence2'        \n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'prem':   premise,\n",
    "       'hyp':     hypothesis}\n",
    "data_json = json.dumps(data)\n",
    "payload = {'json_payload': data_json}\n",
    "headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have our json we can make the request chosen from the endpoints. First we make a simple request, only returning the graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(\"http://172.16.2.104/default\", data=data_json, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the response we get the graphs in nx [MultiDiGraph](https://networkx.github.io/documentation/networkx-1.10/reference/classes.multidigraph.html) format, which we can extract from the jason in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_prem = r.json()['prem']\n",
    "s_hyp = r.json()['hyp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our graphs, we need to import networkx, so we can visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build the objects from the json, for this task we can use the networkx's __json_graph__ class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_prem = json_graph.adjacency.adjacency_graph(s_prem)\n",
    "g_hyp = json_graph.adjacency.adjacency_graph(s_hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have our objects, all we need to do is to visualize them, I used [graphviz](http://graphviz.readthedocs.io/en/stable/manual.html)\n",
    "__dot__ format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = Utils()\n",
    "prem_dot = utils.to_dot(g_prem)\n",
    "hyp_dot = utils.to_dot(g_hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have the dot strings, we can use [Source](http://graphviz.readthedocs.io/en/stable/api.html#source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_prem = Source(prem_dot)\n",
    "v_hyp = Source(hyp_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_prem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_hyp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate similarities between the graphs edges as well, using the method I defined in the utils module. For this first we can get the edges, after we can call __asim_jac__ for calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_prem = utils.get_edges(g_prem)\n",
    "edges_hyp = utils.get_edges(g_hyp)\n",
    "sim = utils.asim_jac(edges_prem, edges_hyp)\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get finer methods, you can use the other two endpoints: __expand__ and __abstract__, with algorithms behind them discussed in the other notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
